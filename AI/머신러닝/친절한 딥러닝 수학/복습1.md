## 신경망, 퍼셉트론
신경망 = 머신러닝의 한 기술, 인간의 뇌를 흉내낸 알고리즘
ANN (Artificial Neural Network)

신경망에는 뉴런을 흉내낸 유닛들이 있고 유닛간의 연결에 가중치가 존재한다
이 가중치를 적절한 값으로 최적화하는것이 머신러닝

문제해결을 위한 가중치와 편향 구하는것이 모델학습의 목표

신경망 = 다층 퍼셉트론
심층신경망 = 신경망의 은닉층이 많은것 (Deep Neural Network)
심층신경망의 가중치와 편향을 구하는것 = 딥러닝


퍼셉트론 = 신경망의 근원이 되는 알고리즘
입력값과 가중치를 곱하고 모두더하고 편향도 더한후에 나온값을 활성화함수에 대입하여 0또는 1을 출력한다
퍼셉트론의 활성화 함수로 계단함수를 이용함

선형분리 가능한 문제만 해결할수있다
선형분리 불가능한 문제를 해결하기 위해 다층퍼셉트론이 나왔다

다층퍼셉트론에서 활성화함수를 쓰지 않는다면 결국 단층퍼셉트론과 같아진다

순전파 = 입력값이 왼쪽에서 오른쪽으로 순차적으로 전달되는 동작 (피드포워드)


---

## 신경망의 가중치와 편향 구하는법

경사하강법을 이용하여 오차함수를 최소로 만드는 가중치와 편향을 구한다 = 최적화문제
오차함수=손실함수=비용함수=목적함수

경사하강법은 함수값을 최소로 만드는 변수값을 구하기 위해 함수를 미분하여 기울기를 구하며 경사를 따라 하강하는 방법이다

목적함수를 미분해야하는데 입력층에서부터 미분하면 합성함수의 미분이 되기 때문에 복잡해진다
출력층에서부터 계산하면 계산식이 간단해지기때문에 뒤에서부터 계산하는데 이것을 오차역전파법이라 한다


## 활성화함수
그리고 이때 활성화함수가 계단함수라면 미분했을때 0이 되기 때문에 경사하강법에서 파라미터갱신을 할수 없게된다
따라서 활성화 함수로 미분했을때 0이 되지 않는 함수를 사용해야한다
시그모이드함수는 x가 0에서 멀어질수록 기울기가 0으로 소실되기 때문에 시그모이드 대신에 ReLu함수를 쓰게 되었다

Rectified Linear Unit 함수




